# Adversarial Logit Pairing

## 甲斐コメント
よくあるパンダのやつみたいなのを間違えにくくなるように学習させるという話。

正直、この分野はどうでも良いというか、詭弁や言いがかりみたいなものと思っているのであまり興味がわかなかった。

提案手法であるロジットペアリングは距離学習に近い概念であると解釈した。

## Abstruct
この論文では、我々は大規模な敵対的な例に対して防御するための改良された技術を開発する。

最初に、我々はこれまでにない規模で最先端の対抗訓練をImageNetに実装し、それがこの状況で効果的であるかどうかを調査します - 重要な未解決の科学的質問です（Athalye et al。、2018）。

次に、ロジットペアリングと呼ばれる手法を使用して強化された防御策を紹介します。これは、例のペアのロジットを類似させる方法です。
ロジットペアリングをクリーンな例とその敵対物に適用すると、バニラの敵対者の訓練よりも敵対例の精度が向上します。
また、2つのデータセットの正確性の点で、クリーンな例のみのロジットペアリングが敵対的トレーニングと競合することもわかりました。

最後に、我々は敵対的なロジットペアリングが1.5％から27.9％への正確さの改善で、PGDホワイトボックス攻撃に対してImagenetの最先端の防御を達成することを示す。
敵対的なロジットペアリングはまた、Imagenetへのブラックボックス攻撃に対する現在の最先端の防御を成功裏に損ない（Tramer et al。、2018）、その正確さを66.6％から47.1％に落とします。この新しい精度の低下で、敵対的なロジットのペアリングはTram`er他と結びつきます。 ImageNetのブラックボックス攻撃に関する最新技術については（2018）を参照。

## 1. Introduction
今日の多くの深層学習モデルは、敵対的な例や誤分類を引き起こすように意図的に最適化されている入力に対して脆弱です。 コンピュータビジョンの文脈では、物体認識分類器は、小さい、しばしば知覚できないほどの摂動で修正された画像を誤って認識します。 さまざまな理由から、敵対的摂動に対してロバストなモデルを開発することが重要です。

- 攻撃者が配備されたシステムの操作を妨害しようと試みる可能性がある状況で機械学習を使用できるようにするため
- 機械学習がモデルベースの最適化により有用であるため
- 分布シフト下のモデルに対して性能保証を提供する方法についてよりよく理解するため
- 滑らかさの仮定などをどのように強制するかについてのより良い理解を得るため

本稿では、このような敵対的な攻撃に対する防御について調査します。 この論文の貢献は以下の通りです。

- 私たちはこれまでにない規模で最先端の対抗訓練を実施し、その有効性をImageNetデータセットで調査します。
- ロジットペアリングは、2対の例のロジットを似たものにする方法です。 私たちは、2つのタイプのロジットペアリング（クリーンと敵対的）を提案します。
- 我々は、クリーンロジットペアリングが、ほとんど2つのデータセットに対する敵対的訓練と同様に、PGDブラックボックス攻撃に対して防御する最小の計算コストでの方法であることを示す。
- 我々は、敵対的ロジットペアリングがホワイトボックス攻撃とブラックボックス攻撃を受けたときにより高い精度をもたらす方法であることを示す。 私たちのモデルは敵対的なロジットペアリングで訓練され、ブラックボックスとホワイトボックスの精度に関して現在の最先端技術を達成しています。
- 私たちは、敵対的な訓練を受けたモデルで構築された攻撃が、ImageNet上のブラックボックス防御の現在の最先端技術に大きなダメージを与えることを示しています（Tramer et al。、2018）。 そして、我々のモデルがこれらの攻撃に対して耐性があることを示します。
