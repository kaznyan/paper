# Data Augmentation using Random Image Cropping

## 甲斐コメント

mixupや「Between-class Learning for Image Classification」の上位互換である。

しかもそれらよりわかりやすく、Keras実装例も落ちている。



画像そのものの合成には間違いなく役立つが、特徴ベクトルの貼り合わせや画像以外の貼り合わせにはどうか？



## Abstruct

CNNのOverfitを防ぐデータ拡張手法としてRICAPを提案する。RICAPでは4つの画像をランダムにトリミングし、それらをパッチして新しいトレーニング画像を作成する。

RICAPにはラベルの平滑化と同様の利点があり、CIFAR-10で2.19％のテストエラーでSOTAを達成した。



## 1. Introduction

データ拡張（旧→新）

- 反転、サイズ変更、ランダムクロッピング
- カラージッタ：輝度、コントラスト、彩度を変化
- カラー変換：主成分分析（PCA）を使用してRGBチャンネルの強度を交互に変える
- ドロップアウト：ピクセルをドロップすることによって画像にノイズを注入する


- カットアウト：画像内の正方形の領域をランダムにマスク（ドロップアウトの拡張）
- ランダム消去：領域をマスクするか、マスク領域のサイズ、縦横比をランダムに決定（カットアウトの亜種）
-  Mixup：2つの画像を合成して新しい画像を形成し、CNNを正則化して画像間の線形挙動を支持する。単にデータ拡張するだけでなく、ラベルスムージングの効果もある。



提案手法：RICAP

- 4つのトレーニング画像をトリミングし、それらをパッチして新しいトレーニング画像を作成
- 画像を選択し、クロップサイズをランダムに決定。最終画像のサイズは元の画像のサイズと同じ
- mixupっぽく、4つの画像のクラスラベルは4つの画像の面積に比例した値
- mixupとの違い：画像を空間的にミックスし、部分的な画像を使用し、元のデータセットにない特徴は生成されない

→従来の技術と同じようにCNNに適用できるデータ拡張手法

→ラベルスムージング手法の1種ともとれる

→CIFAR-10でSOTA

→CNNが画像内のさまざまな物体や特徴に注目できる

→画像キャプションの取得タスクにも適する



## 2. 関連研究

mixupの長所

- CNNがトレーニングサンプル間の線形動作を学習

  →よりスムーズな推定とマージン最大化

- トレーニング画像の種類を増やす

- 敵対的摂動のようにも機能し、CNNを敵対的な例に対して頑強にする

  →GANの安定化にも貢献

- ラベルスムージング

  →推定されたクラスに対する0 / 1を過剰に追及することを防ぐ



## 3. 提案手法

RICAP

- トレーニングセットから4つの画像をランダムに選択

- 画像を別々にトリミング

- トリミングされた画像をパッチ

- ラベルの作り方：面積比

  ​

→過学習の防止とラベルスムージング

![キャプチャ](C:\Users\d184813\Desktop\論文\おわ\20190401__★★★★★__Data Augmentation using Random Image Cropping\キャプチャ.PNG)



→マスクにより情報が失われないためカットアウト等の上位互換である



## 4. 実験と結果

#### A. CIFAR

前処理

- 画像の各チャンネルをゼロ平均および単位分散に正規化

- 両側に４ピクセルのパディング

- 32x32 のランダムクロップ

- 水平方向のランダムフリップ

  ​

結果：既存手法より優れたエラー率



ハイパーパラメーターβについて

- 0.3が最良のテストエラー率

- 大きすぎると、ベースラインよりも悪い結果

  →過度のラベルスムージングは悪影響

- 減少するにつれて、ベースラインの結果に収束（元の画像と同じ感じになるため）



#### B. Imagenet

前処理

- 画像の各チャンネルをゼロ平均および単位分散に正規化
- ランダムリサイズ
- ランダムクロップ
- カラージッタ
- 光
- 水平方向のランダムフリップ



結果

- 他の手法より収束が早く精度も良い

- ハイパーパラメータ β=0.3 がImagenetとCIFARの両方に適用可 → 頑健

  （mixupはパラメータ調整が地味に難しく、Imagenetでは0.2、CIFAR10では1.0）



#### C. 他のアーキテクチャでの分類

結果

- 他のアーキテクチャでも高い性能を示し、β=0.3も不変
- 特にShake-Shakeと相性が良くテストエラー率2.19%を達成（SOTA）



#### D. 注目している特徴の可視化 

特定の領域の特徴に頼りすぎず、同じ画像からより広範な特徴を使用できる

![キャプチャ3](C:\Users\d184813\Desktop\論文\おわ\20190401__★★★★★__Data Augmentation using Random Image Cropping\キャプチャ3.PNG)



#### その他の検討

- 分類以外のタスクにも良い効果があった
- mixupでは4画像を合成するとうまくいかなかったが、情報がロスしないRICAPはうまくいく
- ラベルを0 / 1にするとうまくいかない