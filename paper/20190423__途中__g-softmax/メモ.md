# G-Softmax



## Abstract

G-softmax

- クラス内コンパクト性とクラス間分離性を効果的に向上させることができるガウスベースのSoftmax

- 実現が簡単で容易に置き換えることができる

- すべての評価されたデータセットにわたって最先端のモデルを改善

- 良好な特徴（性能の向上と一致）

- クラス内コンパクト性およびクラス間分離性が、MS COCOおよびNUS-WIDEの平均精度と直線的に相関

  ⇒クラス内のコンパクト性とクラス間の分離性が向上すると平均精度が向上



## 1.Introduction

モデルを設計/評価するときの目的

- 正確な予測を達成するためにモデルをどれだけ複雑にするか
- 単純ではないモデルをどこまで単純に設計できるか



前提

- softmaxは以前に観測されたサンプルの分布パターンを考慮に入れない
- 重みがガウス分布に従い、分類のためにその分布パターンを利用する
- 特徴のクラス内コンパクト性およびクラス間分離可能性は一般に、学習された特徴の品質と相関している



⇒提案手法：G-softmax

- Gaussianベースのsoftmax
- ガウス累積分布関数（CDF）が予測と正規化に使用され、ソフトな形で最終的な信頼度が生成される



## 2. Related Work

（前略）

マルチラベル分類

- ラベル相関をモデル化するための分類連鎖モデル（Read et al.）
  - ラベルの順序はチェーン分類モデルにとって重要

- 動的計画法に基づく分類子連鎖アルゴリズム（Shen et al. ）
  - 分類子連鎖モデルに対する大域的に最適なラベルの順序を見つけるために提案された
  - クロスビュー学習の観点からラベル相関を探求するCo-EmbeddingとCo-Hashing
  - ラベルの難易度を考慮していない

- 簡単なラベルからの予測を有効に利用して、難しいラベルからの予測を改善する学習パラダイム

- マルチラベル注釈問題のためのスパースコーディングツリーフレームワーク（Liu et al.）
  - 決定木モデルの次元の呪いに関する包括的な理論的分析を提示

- ラージマージンメトリック学習パラダイム（Liu et al）
  - 理論的保証付きの多出力問題のための適切な距離計量を効率的に学習する方法
  - 正準相関分析および最大マージン出力符号化方法における復号化手順の複雑さを軽減



## 3. 理論

