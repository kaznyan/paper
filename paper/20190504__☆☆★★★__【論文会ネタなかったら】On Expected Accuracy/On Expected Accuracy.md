# On Expected Accuracy



## 甲斐コメント

- すごい怪しげな風貌とタイトルの論文だが、結果は出ている。
- 「精度ベースのロス関数を使った」という書き方だが、「クロスエントロピーを拡張した」ってのが普通の感覚なんだろうね
- 結局、クロスエントロピー一辺倒でも、なに一辺倒でもなく、これがいいんじゃないかと思う要素をどんどん損失関数に突っ込んだらいいんじゃないかな？
- あまり勉強になる感じの論文ではないけど、ネタ的にはいいかなって感じ



## Abstract

クロスエントロピー（負の対数尤度）に対する代替の損失関数としての（負の）期待精度

- クロスエントロピーと比較して同等またはそれ以上の精度
- ラベルノイズに対してよりロバスト



## 1. Introduction

最尤アプローチDis

- CrossEntropy & Softmaxでいいの？
- テスト時にはモデルのエラー率を比較しているけど、制度を直接最適化すればいいんじゃないの？
  - 微分可能ではない問題
  - 尤度アプローチには良い特性がいっぱいあるから

- 決定の境界にどれほど近いかは関係ない。誤りは誤りだから



精度を見るやつの既存研究

- 0-1の損失の上限を定めるサロゲート損失関数
  - サロゲートリスクを最適化
- サポートベクターマシンにおけるヒンジ損失などのマージンベースの損失関数
  - 確率的対数尤度アプローチに対する代替案
- 二乗誤差損失やブースティング損失などのフィッシャー矛盾のない損失関数



提案手法

- 負の予測精度（またはエラー率）を調べる
- データ分布ではなくモデル分布に対する期待値を定義しても、実際の精度に近い損失関数（または0〜1の損失）が得られることを示す
- 最適化の困難さを克服するためにLeakyバージョンを調べる
- 従来の対数尤度損失と比較



## 2. Methodology

###### 簡単な定義

![キャプチャ](画像\キャプチャ.PNG)

![キャプチャ2](画像\キャプチャ2.PNG)

- Accuracy（0-1 function）をGradientベースの方法で最適化できない（微分不可能であるため）ので近似の関数として用意したという意味もある

###### Leaky Version

![キャプチャ3](画像\キャプチャ3.PNG)

- SoftmaxCrossEntropy的なのを加えただけ

- y = 0に近いときにちゃんと大きめの傾斜を持ってくれる

  ![キャプチャ4](画像\キャプチャ4.PNG)



## 3. Experiments

###### 予備実験：MNIST（Leakyでないものを使った場合）

- 精度が良くなるが、訓練の初期段階で性能の一時的な停滞がある
- 9:1の分割が異なると初期プラトーが異なる
- 精度が初期プラトーを超えられず低く収まった試行もある



###### 様々なArchitecture & タスクでの実験

- Architecture：（MLP, CNN, Bidirectional LSTM, Tree LSTM）

- データ：TrainingセットとTestセットの各インスタンスにランダムラベル（確率0.05）をランダムに割り当てるノイズの多いラベル設定でも実験する

- 結果：同程度かやや優れた。ノイズの多いラベル設定では顕著に優れた。

  ![キャプチャ5](画像\キャプチャ5.PNG)



## 4. Conclusion And Future Work

精度・エラー率（のLeakyバージョン）を分類目的として調査

- 少なくとも対数尤度と同等に機能し、場合によって改善もあった
- 精度に対してより忠実な近似を提供する

汎化を考慮して訓練を最適化

- テスト関数の損失関数を比較して汎化性能を評価できるよう工夫

対数尤度・クロスエントロピー・Softmaxを使う大体の研究を代替して進歩させる可能性がある